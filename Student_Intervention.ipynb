{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Building a Student Intervention System\n",
    "## Goal: Evaluate Performance of Different Supervised Learning Models and Implement Parameter Tuning\n",
    "\n",
    "In this project, we evaluate the performance and predictive power of different classification models on student performance data [provided by Udacity](https://github.com/udacity/machine-learning/tree/master/projects/student_intervention). We then pick the best of them and implement parameter tuning using Grid Search to improve its predictive performance on our testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "We begin by importing some libraries and reading the data. Then, we investigate the dataset to determine how many students we have information on, and learn about the graduation rate among these students.\n",
    "\n",
    "Note that the last column from this dataset, `'passed'`, will be our target label (whether the student graduated or didn't graduate). All other columns are features about each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of features: 30\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of students\n",
    "nlines, ncol = student_data.loc[:,student_data.columns != 'passed'].shape\n",
    "n_students = nlines\n",
    "\n",
    "# Calculate number of features\n",
    "n_features = ncol\n",
    "\n",
    "# Calculate passing students\n",
    "n_passed = len(student_data[student_data.passed == 'yes'])\n",
    "\n",
    "# Calculate failing students\n",
    "n_failed = len(student_data[student_data.passed == 'no'])\n",
    "\n",
    "# Calculate graduation rate\n",
    "grad_rate = float(n_passed)/n_students * 100\n",
    "\n",
    "# Print the results\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "In this section, we prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "We first separate the student data into feature and target columns to see if any features are non-numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Target column: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extract target column 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print \"Feature columns:\\n{}\".format(feature_cols)\n",
    "print \"\\nTarget column: {}\".format(target_col)\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Feature Columns\n",
    "\n",
    "Based on the data-head that we printed above, there are several non-numeric columns that need to be converted. Some of those columns (e.g.  `Mjob` and `Fjob`) contain _categorical variables_ (i.e. variables with more than two values). We deal with these columns by creating _dummy variables_, using the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Data Split\n",
    "After converting all _categorical_ features into numeric values we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 300 samples.\n",
      "Testing set has 95 samples.\n"
     ]
    }
   ],
   "source": [
    "# Set the number of training points\n",
    "num_train = 300\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# Shuffle and split the dataset into the number of training and testing points above\n",
    "# Stratify will maintain the class imbalance across both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=num_train, random_state=2, stratify=y_all)\n",
    "\n",
    "# Show the results of the split\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating Models\n",
    "In this section, we compare supervised learning models that are appropriate for this problem and available in `scikit-learn`. More specifically, we compare Gaussian Naive Bayes, Decision Trees and Gradient Boosting. We fit all models to varying sizes of training data (100 data points, 200 data points, and 300 data points) and measure the F<sub>1</sub> score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "The code cell below contains three helper functions which are used for training and testing the three supervised learning models we mentioned above. The functions are as follows:\n",
    "- `train_classifier` - takes as input a classifier and training data and fits the classifier to the data.\n",
    "- `predict_labels` - takes as input a fit classifier, features, and a target labeling and makes predictions using the F<sub>1</sub> score.\n",
    "- `train_predict` - takes as input a classifier, and the training and testing data, and performs `train_clasifier` and `predict_labels`.\n",
    " - This function will report the F<sub>1</sub> score for both the training and testing data separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print \"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Model Performance Metrics\n",
    "With the predefined functions above, we now import the three supervised learning models and run the `train_predict` function for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a GaussianNB using a training set size of 100. . .\n",
      "Trained model in 0.0037 seconds\n",
      "Made predictions in 0.0010 seconds.\n",
      "F1 score for training set: 0.8696.\n",
      "Made predictions in 0.0008 seconds.\n",
      "F1 score for test set: 0.7023.\n",
      "Training a GaussianNB using a training set size of 200. . .\n",
      "Trained model in 0.0012 seconds\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for training set: 0.8333.\n",
      "Made predictions in 0.0009 seconds.\n",
      "F1 score for test set: 0.6984.\n",
      "Training a GaussianNB using a training set size of 300. . .\n",
      "Trained model in 0.0029 seconds\n",
      "Made predictions in 0.0007 seconds.\n",
      "F1 score for training set: 0.8155.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.7188.\n",
      "Training a DecisionTreeClassifier using a training set size of 100. . .\n",
      "Trained model in 0.0303 seconds\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for test set: 0.7218.\n",
      "Training a DecisionTreeClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0016 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0002 seconds.\n",
      "F1 score for test set: 0.7407.\n",
      "Training a DecisionTreeClassifier using a training set size of 300. . .\n",
      "Trained model in 0.0025 seconds\n",
      "Made predictions in 0.0007 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.7559.\n",
      "Training a GradientBoostingClassifier using a training set size of 100. . .\n",
      "Trained model in 0.1224 seconds\n",
      "Made predictions in 0.0268 seconds.\n",
      "F1 score for training set: 1.0000.\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for test set: 0.7429.\n",
      "Training a GradientBoostingClassifier using a training set size of 200. . .\n",
      "Trained model in 0.1129 seconds\n",
      "Made predictions in 0.0009 seconds.\n",
      "F1 score for training set: 0.9928.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.7971.\n",
      "Training a GradientBoostingClassifier using a training set size of 300. . .\n",
      "Trained model in 0.1232 seconds\n",
      "Made predictions in 0.0014 seconds.\n",
      "F1 score for training set: 0.9639.\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for test set: 0.7801.\n"
     ]
    }
   ],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the three models\n",
    "clf_A = GaussianNB()\n",
    "clf_B = DecisionTreeClassifier(random_state=1)\n",
    "clf_C = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "# Set up the training set sizes\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train\n",
    "y_train_300 = y_train\n",
    "\n",
    "# Execute the 'train_predict' function for each classifier and each training set size\n",
    "# train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "for clfi in [clf_A, clf_B, clf_C]:\n",
    "    for X_traini, y_traini in [[X_train_100, y_train_100],[X_train_200, y_train_200],[X_train_300, y_train_300]]:\n",
    "        train_predict(clfi, X_traini, y_traini, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Results\n",
    "\n",
    "The results are summarized below:\n",
    "\n",
    "** Classifer 1 - Gaussian Naive Bayes**  \n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 100               |        0.0037           |      0.0008            |       0.8696     |     0.7023      |\n",
    "| 200               |        0.0012           |      0.0009            |       0.8333     |     0.6984      |\n",
    "| 300               |        0.0029           |      0.0005            |       0.8155     |     0.7188      |\n",
    "\n",
    "** Classifer 2 - Decision Trees**  \n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 100               |        0.0303           |      0.0004            |       1.0000     |     0.7218      |\n",
    "| 200               |        0.0016           |      0.0002            |       1.0000     |     0.7407      |\n",
    "| 300               |        0.0025           |      0.0003            |       1.0000     |     0.7559      |\n",
    "\n",
    "** Classifer 3 - Gradient Boosting**  \n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 100               |        0.1224           |       0.0006           |       1.0000     |     0.7429      |\n",
    "| 200               |        0.1129           |       0.0005           |       0.9928     |     0.7971      |\n",
    "| 300               |        0.1232           |       0.0006           |       0.9639     |     0.7801      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Best Model\n",
    "From the tabular data presented above it seems that the gradient boosting model performs the best. For most training sets it seems to performs better on the test set than the corresponding results from the other models. Gradient boosting seems to perform especially well even with small data sets (training set of 100) comparing to the other models we tried. Its training time is greater than Gaussian Naive Bayes and Decision Trees but the prediction time is approximately the same in all cases. If we are given a large training set, as training time could become an important issue, we might choose to use the Gaussian Naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Model Tuning\n",
    "Here we fine tune the chosen model using grid search (`GridSearchCV`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters picked: {'n_estimators': 10, 'max_depth': 3}\n",
      "Made predictions in 0.0010 seconds.\n",
      "Tuned model has a training F1 score of 0.8596.\n",
      "Made predictions in 0.0003 seconds.\n",
      "Tuned model has a testing F1 score of 0.7973.\n"
     ]
    }
   ],
   "source": [
    "# Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "parameters = {'n_estimators':[5,10,25,50,100,200],'max_depth':[2,3]}\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "# Make an f1 scoring function using 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score,pos_label='yes')\n",
    "\n",
    "# Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf, param_grid=parameters, scoring=f1_scorer)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "print \"Best parameters picked:\", grid_obj.best_params_\n",
    "print \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x119f278d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApoAAAIwCAYAAAAmi8t3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a5ef10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the results using seaborn heatmap\n",
    "\n",
    "# Import seaborn and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Make dataframe with tuning parameters as columns\n",
    "grid_long = pd.DataFrame(grid_obj.grid_scores_)\n",
    "grid_long['n_estimators'] = [i['n_estimators'] for i in grid_long.parameters]\n",
    "grid_long['max_depth'] = [i['max_depth'] for i in grid_long.parameters]\n",
    "\n",
    "# Pivot dataframe to set max_depth as index\n",
    "grid = grid_long.pivot(index=\"max_depth\",columns=\"n_estimators\",values=\"mean_validation_score\")\n",
    "\n",
    "# Plot results\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(grid, annot=True, fmt='.3g')\n",
    "ax.set_title(\"Best parameters picked: {}\".format(grid_obj.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final F<sub>1</sub> Score\n",
    "The final testing test score for a training set of 300 improved significantly, using 10 estimators (instead of 100) and a max depth of 3 (unchanged):\n",
    "\n",
    "Final F1 score: 0.8596 (training), 0.7973 (testing).\n",
    "\n",
    "Untuned F1 score: 0.9639 (training), 0.7801 (testing).\n",
    "\n",
    "Now that we optimized our model using the F<sub>1</sub> score we can also evaluate the classification accuracy of the model for the parameters we picked above. This will give us a better idea of how well our parameters perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model has a testing accuracy score of 0.6842.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_guess = clf.predict(X_test)\n",
    "print \"Tuned model has a testing accuracy score of {:.4f}.\".format(accuracy_score(y_test,y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graduation rate is 67.09% and our accuracy score is 68.42%. This means that our model does not perform much better than a model that would predict that every student in the class will graduate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
